{
	  "container": {
		    "type": "DOCKER",
		    "docker": {
		      "image": "yanglei99/spark_mesosphere_mesos",
		      "network": "HOST",
		      "portMappings": [ ]
		    },
			"volumes": [
			      {
			    	  "containerPath": "/spark/job/workload.py",
			    	  "hostPath": "./workload.py",
			          "mode": "RW"
			      },
			      {
			    	  "containerPath": "/spark/job/stocator-1.0.8-SNAPSHOT-jar-with-dependencies.jar",
			    	  "hostPath": "./stocator-1.0.8-SNAPSHOT-jar-with-dependencies.jar",
			          "mode": "RW"
			      }
			]
		  },
    "id": "spark.es",
    "cpus": 3,
    "mem": 6144,
    "instances": 1,
    "acceptedResourceRoles": ["slave_public"],
    "uris": [
             "https://s3-us-west-1.amazonaws.com/mydata.yl/workload.py",
             "https://s3-us-west-1.amazonaws.com/mydata.yl/stocator-1.0.8-SNAPSHOT-jar-with-dependencies.jar"
             ],
    "env": {
        "ST_KEY":"YOUR KEY",
        "ST_USER":"YOUR Account:YOUR User",
        "ST_AUTH":"https://sjc01.objectstorage.softlayer.net/auth/v1.0",
        "ST_CONTAINER":"YOUR CONTAINER",
        "SAMPLE_RATIO":"1",
        "REPEAT":"5",
        "PARTITION_NUM":"4",
        "FILENAME_SUFFIX_PATTERN":"(index)",
        "START_INDEX":"0",
        "FORMAT":"es",
        "DATASTORE":"spark/workload",
        "SPARK_ADDITIONAL_CONFIG":"--conf spark.es.batch.size.entries=8000 --conf spark.es.index.auto.create=true --conf spark.cores.max=30 --conf spark.executor.memory=5g --conf spark.executor.cores=4 --conf spark.mesos.executor.docker.image=yanglei99/spark_mesosphere_mesos --conf spark.es.nodes.discovery=false --conf spark.es.nodes.wan.only=true --conf spark.es.nodes=127.0.0.1",
        "SPARK_ADDITIONAL_JARS":"--packages com.databricks:spark-csv_2.11:1.5.0,org.elasticsearch:elasticsearch-spark-20_2.11:5.0.0 --jars stocator-1.0.8-SNAPSHOT-jar-with-dependencies.jar",
        "SPARK_JOB": "workload.py put"
    }
}
